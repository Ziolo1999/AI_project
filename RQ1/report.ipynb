{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/karol/Desktop/Antwerp/ai_project\")\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import MLP1, TwoTower\n",
    "from data_reader import load_data, data_preprocessing, load_data_mf, customer_buckets\n",
    "from helper import validate_softmax,  train_softmax, train_two_tower\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions, articles, customers, article_encodings, customer_encodings = data_preprocessing(feature_generation=False, return_encodings=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data and apply one hot encoding for articles and customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "transactions = pd.read_csv(\"data/preprocessed/transactions.csv\") \n",
    "articles = pd.read_csv(\"data/preprocessed/articles.csv\") \n",
    "customers = pd.read_csv(\"data/preprocessed/customers.csv\") \n",
    "\n",
    "# one hot encoding \n",
    "articles = articles.set_index(\"article_id\")\n",
    "customers = customers.set_index(\"customer_id\")\n",
    "\n",
    "article_enc = OneHotEncoder(sparse_output=True)\n",
    "articles = article_enc.fit_transform(articles)\n",
    "\n",
    "customers_categorical = [\"FN\",'Active',\"club_member_status\", \"fashion_news_frequency\"]\n",
    "customers_cont = [\"age\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), customers_categorical),\n",
    "        ('cont', 'passthrough', customers_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "customers = csr_matrix(preprocessor.fit_transform(customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data & Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = load_data(transactions, train_test=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & Train basic Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create model\n",
    "# model = MLP1(input_dim=n_articles, output_dim=n_articles)\n",
    "# # get params\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# save_dir = \"models/MLP1.pt\"\n",
    "# # train\n",
    "# val_loss_list, val_acc_list = train_softmax(model, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1 = torch.load(\"KarolZiolo/RQ1/models/MLP1.pt\")\n",
    "criterion = nn.MSELoss()\n",
    "#final validation accuracy\n",
    "val_loss, val_accuracy = validate_softmax(MLP1, val_dataloader, criterion, k=3)\n",
    "val_accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for improvements:\n",
    "- No warm start\n",
    "- Model should be trained on customers who had at least two purchases\n",
    "- We take into account baskets which are based on the past 2 years. Maybe we should train model based on customers who bought articles in last month.\n",
    "- Different way to measure accuracy.\n",
    "- Customers whou didn't developed any patterns (bought low amount of clothes) should be recommended with current top selling articles.\n",
    "- Develop more complex (deeper) model.\n",
    "- More training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization with DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = load_data_mf(transactions, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = customer_buckets(transactions, train_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 90/285884 [00:32<28:49:21,  2.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/report.ipynb Cell 18\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/report.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/report.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m save_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mKarolZiolo/RQ1/models/TwoTower1.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/karol/Desktop/Antwerp/ai_project/AI_project/RQ1/report.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_two_tower(model, customers, articles, buckets, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Antwerp/ai_project/AI_project/RQ1/helper.py:78\u001b[0m, in \u001b[0;36mtrain_two_tower\u001b[0;34m(model, customers, articles, buckets, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs)\u001b[0m\n\u001b[1;32m     76\u001b[0m customer_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(customers[customers_id]\u001b[39m.\u001b[39mtodense(), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     77\u001b[0m \u001b[39m# Generate negative samplings\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m random_negative_articles \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mlist\u001b[39m(all_articles_set\u001b[39m-\u001b[39m\u001b[39mset\u001b[39m(buckets[cstmr\u001b[39m.\u001b[39mitem()]))) \u001b[39mfor\u001b[39;00m cstmr \u001b[39min\u001b[39;00m customers_id])\n\u001b[1;32m     79\u001b[0m negative_articles_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(articles[random_negative_articles]\u001b[39m.\u001b[39mtodense(), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Stack positives with negatives\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Antwerp/ai_project/AI_project/RQ1/helper.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m customer_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(customers[customers_id]\u001b[39m.\u001b[39mtodense(), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     77\u001b[0m \u001b[39m# Generate negative samplings\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m random_negative_articles \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(\u001b[39mlist\u001b[39;49m(all_articles_set\u001b[39m-\u001b[39;49m\u001b[39mset\u001b[39;49m(buckets[cstmr\u001b[39m.\u001b[39;49mitem()]))) \u001b[39mfor\u001b[39;00m cstmr \u001b[39min\u001b[39;00m customers_id])\n\u001b[1;32m     79\u001b[0m negative_articles_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(articles[random_negative_articles]\u001b[39m.\u001b[39mtodense(), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Stack positives with negatives\u001b[39;00m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:997\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:781\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/_bounded_integers.pyx:1315\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.17/envs/ai_project/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2974\u001b[0m, in \u001b[0;36m_prod_dispatcher\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2960\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2961\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2962\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2968\u001b[0m \u001b[39m    ndarray.min : equivalent method\u001b[39;00m\n\u001b[1;32m   2969\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2970\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39mminimum, \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, axis, \u001b[39mNone\u001b[39;00m, out,\n\u001b[1;32m   2971\u001b[0m                           keepdims\u001b[39m=\u001b[39mkeepdims, initial\u001b[39m=\u001b[39minitial, where\u001b[39m=\u001b[39mwhere)\n\u001b[0;32m-> 2974\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prod_dispatcher\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2975\u001b[0m                      initial\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, where\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2976\u001b[0m     \u001b[39mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   2979\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2980\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2981\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_article_dim = articles.shape[1]\n",
    "input_customer_dim = customers.shape[1]\n",
    "model = TwoTower(input_article_dim, input_customer_dim, output_dim=3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "save_dir = \"KarolZiolo/RQ1/models/TwoTower1.pt\"\n",
    "train_two_tower(model, customers, articles, buckets, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
