{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/karol/Desktop/Antwerp/ai_project\")\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import MLP1, TwoTower\n",
    "from data_reader import load_data, data_preprocessing, load_data_mf\n",
    "from helper import validate_softmax,  train_softmax, train_two_tower\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions, articles, customers, article_encodings, customer_encodings = data_preprocessing(feature_generation=False, return_encodings=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data and apply one hot encoding for articles and customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "transactions = pd.read_csv(\"data/preprocessed/transactions.csv\") \n",
    "articles = pd.read_csv(\"data/preprocessed/articles.csv\") \n",
    "customers = pd.read_csv(\"data/preprocessed/customers.csv\") \n",
    "\n",
    "# one hot encoding \n",
    "articles = articles.set_index(\"article_id\")\n",
    "customers = customers.set_index(\"customer_id\")\n",
    "\n",
    "article_enc = OneHotEncoder(sparse_output=True)\n",
    "articles = article_enc.fit_transform(articles)\n",
    "\n",
    "customers_categorical = [\"FN\",'Active',\"club_member_status\", \"fashion_news_frequency\"]\n",
    "customers_cont = [\"age\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(sparse_output=True), customers_categorical),\n",
    "        ('cont', 'passthrough', customers_cont)  # 'passthrough' means no transformation for continuous variables\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not explicitly transformed\n",
    ")\n",
    "customers = csr_matrix(preprocessor.fit_transform(customers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data & Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = load_data(transactions, train_test=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & Train basic Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create model\n",
    "# model = MLP1(input_dim=n_articles, output_dim=n_articles)\n",
    "# # get params\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# save_dir = \"models/MLP1.pt\"\n",
    "# # train\n",
    "# val_loss_list, val_acc_list = train_softmax(model, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP1 = torch.load(\"KarolZiolo/RQ1/models/MLP1.pt\")\n",
    "criterion = nn.MSELoss()\n",
    "#final validation accuracy\n",
    "val_loss, val_accuracy = validate_softmax(MLP1, val_dataloader, criterion, k=3)\n",
    "val_accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for improvements:\n",
    "- No warm start\n",
    "- Model should be trained on customers who had at least two purchases\n",
    "- We take into account baskets which are based on the past 2 years. Maybe we should train model based on customers who bought articles in last month.\n",
    "- Different way to measure accuracy.\n",
    "- Customers whou didn't developed any patterns (bought low amount of clothes) should be recommended with current top selling articles.\n",
    "- Develop more complex (deeper) model.\n",
    "- More training. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization with DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader = load_data_mf(transactions, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_article_dim = articles.shape[1]\n",
    "input_customer_dim = customers.shape[1]\n",
    "model = TwoTower(input_article_dim, input_customer_dim, output_dim=3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "save_dir = \"KarolZiolo/RQ1/models/TwoTower1.pt\"\n",
    "train_two_tower(model, customers, articles, train_dataloader, val_dataloader, criterion, optimizer, save_dir, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
